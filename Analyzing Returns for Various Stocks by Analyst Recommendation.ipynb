{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26e776da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do more highly-recommended stocks outperform lowly-rated ones?\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cm\n",
    "import sqlite3\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "pd.set_option('display.max_columns',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "042fdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all SP500 companies\n",
    "query=pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')\n",
    "sp500 = list(query[0]['Symbol'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe6793db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history_and_recommendation_data(stock_ticker,period='5y',days_out=180,min_recommendations=5):\n",
    "    # Prepare yfinance\n",
    "    print('Results for: '+stock_ticker)\n",
    "    stock=yf.Ticker(stock_ticker)\n",
    "    \n",
    "    # Get historical trading data\n",
    "    try:\n",
    "        history=stock.history(period=period)\n",
    "    except:\n",
    "        print('No history data for '+stock_ticker)\n",
    "        return\n",
    "    \n",
    "    # Get recommendations\n",
    "    try:\n",
    "        recommendations=stock.recommendations.reset_index().sort_values(by=['Firm','Date'])\n",
    "    except:\n",
    "        print('No analyst recommendation data for '+stock_ticker)\n",
    "        return\n",
    "    recommendations['Next Recommendation']=recommendations.groupby('Firm')['Date'].shift(-1)\n",
    "    recommendations[str(days_out)+' Days From']=recommendations['Date']+pd.Timedelta(days=days_out)\n",
    "    recommendations['Good Until']=recommendations\\\n",
    "        [['Next Recommendation',str(days_out)+' Days From']]\\\n",
    "            .min(axis=1) # Define how long a recommendation lasts for - lowest of [days_out] or\n",
    "                # [Until a new recommendation by that firm]\n",
    "\n",
    "    # Process the recommendation values\n",
    "    print('Recommendation values: '\\\n",
    "          +str(sorted(recommendations['To Grade'].dropna().unique()))) # Print out the unique recommendation grades\n",
    "    assign_values = {'Buy':4, 'Equal-Weight':3, 'Hold':3, 'Market Perform':3, 'Neutral':3,\n",
    "       'Outperform':4, 'Overweight':4, 'Peer Perform':3, 'Positive':4, 'Reduce':2,\n",
    "       'Sector Perform':3, 'Sector Weight':3, 'Sell':1, 'Strong Buy':5, 'Strong Sell':1, 'Underperform':1,\n",
    "       'Underweight':1} # Create numeric representations of the recommendations\n",
    "    recommendations['Assigned Value']=\\\n",
    "    recommendations['To Grade'].replace(assign_values) # Give the numeric representations a column\n",
    "    \n",
    "    # Store the dataframes in sqlite memory\n",
    "    conn = sqlite3.connect(':memory:')\n",
    "    history.to_sql('history', conn, index=True)\n",
    "    recommendations.to_sql('recommendations', conn, index=False)\n",
    "    \n",
    "    # Get average analyst assigned scores by day using SQL\n",
    "    qry = '''\n",
    "    select h.open, h.high, h.low, h.close, h.volume, date(h.date) as Date, avg(r.'assigned value') as 'Average Assigned Value',\n",
    "    count(r.'assigned value') as 'Count of Ratings'\n",
    "    from history h\n",
    "    left join ( \n",
    "    select * from recommendations r \n",
    "    where r.firm in \n",
    "    (select firm from recommendations group by firm having count(date)>='''+str(int(min_recommendations))+''')\n",
    "        -- Join recommendations, but only for firms with at least minimum recommendations recommendations\n",
    "    ) r\n",
    "    on date(h.date) between date(r.date) and date(r.'good until')\n",
    "    group by h.open, h.high, h.low, h.close, h.volume, date(h.date)\n",
    "        '''\n",
    "    df = pd.read_sql_query(qry, conn).sort_values(by='Date')\n",
    "    df['Date']=pd.to_datetime(df['Date'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2dbe62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for: AAPL\n",
      "Recommendation values: ['', 'Buy', 'Equal-Weight', 'Equal-weight', 'Hold', 'Long-Term Buy', 'Long-term Buy', 'Market Outperform', 'Market Perform', 'Negative', 'Neutral', 'Outperform', 'Overweight', 'Peer Perform', 'Perform', 'Positive', 'Reduce', 'Sector Outperform', 'Sector Perform', 'Sector Weight', 'Sell', 'Strong Buy', 'Underperform', 'Underweight']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Average Assigned Value</th>\n",
       "      <th>Count of Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.412197</td>\n",
       "      <td>31.586868</td>\n",
       "      <td>31.334303</td>\n",
       "      <td>31.461763</td>\n",
       "      <td>92141600</td>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>3.844444</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.504256</td>\n",
       "      <td>31.886640</td>\n",
       "      <td>31.452327</td>\n",
       "      <td>31.870119</td>\n",
       "      <td>132904800</td>\n",
       "      <td>2017-02-14</td>\n",
       "      <td>3.844444</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.988130</td>\n",
       "      <td>32.165160</td>\n",
       "      <td>31.775692</td>\n",
       "      <td>31.985767</td>\n",
       "      <td>142492400</td>\n",
       "      <td>2017-02-15</td>\n",
       "      <td>3.844444</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.023538</td>\n",
       "      <td>32.077827</td>\n",
       "      <td>31.827625</td>\n",
       "      <td>31.948008</td>\n",
       "      <td>90338400</td>\n",
       "      <td>2017-02-16</td>\n",
       "      <td>3.844444</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.889007</td>\n",
       "      <td>32.061315</td>\n",
       "      <td>31.889007</td>\n",
       "      <td>32.035351</td>\n",
       "      <td>88792800</td>\n",
       "      <td>2017-02-17</td>\n",
       "      <td>3.844444</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>172.860001</td>\n",
       "      <td>173.949997</td>\n",
       "      <td>170.949997</td>\n",
       "      <td>171.660004</td>\n",
       "      <td>77251200</td>\n",
       "      <td>2022-02-07</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>171.729996</td>\n",
       "      <td>175.350006</td>\n",
       "      <td>171.429993</td>\n",
       "      <td>174.830002</td>\n",
       "      <td>74829200</td>\n",
       "      <td>2022-02-08</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>176.050003</td>\n",
       "      <td>176.649994</td>\n",
       "      <td>174.899994</td>\n",
       "      <td>176.279999</td>\n",
       "      <td>71285000</td>\n",
       "      <td>2022-02-09</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>174.139999</td>\n",
       "      <td>175.479996</td>\n",
       "      <td>171.550003</td>\n",
       "      <td>172.119995</td>\n",
       "      <td>90865900</td>\n",
       "      <td>2022-02-10</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>172.330002</td>\n",
       "      <td>173.080002</td>\n",
       "      <td>168.039993</td>\n",
       "      <td>168.639999</td>\n",
       "      <td>98566000</td>\n",
       "      <td>2022-02-11</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1260 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open        High         Low       Close     Volume       Date  \\\n",
       "0      31.412197   31.586868   31.334303   31.461763   92141600 2017-02-13   \n",
       "1      31.504256   31.886640   31.452327   31.870119  132904800 2017-02-14   \n",
       "3      31.988130   32.165160   31.775692   31.985767  142492400 2017-02-15   \n",
       "4      32.023538   32.077827   31.827625   31.948008   90338400 2017-02-16   \n",
       "2      31.889007   32.061315   31.889007   32.035351   88792800 2017-02-17   \n",
       "...          ...         ...         ...         ...        ...        ...   \n",
       "1237  172.860001  173.949997  170.949997  171.660004   77251200 2022-02-07   \n",
       "1230  171.729996  175.350006  171.429993  174.830002   74829200 2022-02-08   \n",
       "1249  176.050003  176.649994  174.899994  176.279999   71285000 2022-02-09   \n",
       "1239  174.139999  175.479996  171.550003  172.119995   90865900 2022-02-10   \n",
       "1233  172.330002  173.080002  168.039993  168.639999   98566000 2022-02-11   \n",
       "\n",
       "      Average Assigned Value  Count of Ratings  \n",
       "0                   3.844444                45  \n",
       "1                   3.844444                45  \n",
       "3                   3.844444                45  \n",
       "4                   3.844444                45  \n",
       "2                   3.844444                45  \n",
       "...                      ...               ...  \n",
       "1237                3.857143                21  \n",
       "1230                3.857143                21  \n",
       "1249                3.857143                21  \n",
       "1239                3.857143                21  \n",
       "1233                3.857143                21  \n",
       "\n",
       "[1260 rows x 8 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl=get_history_and_recommendation_data('AAPL')\n",
    "aapl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f6b8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_rating_and_return(df,minimum_average_ratings=3,trim_start=100):\n",
    "    df=df.iloc[100:,:]\n",
    "    if df['Count of Ratings'].mean() < minimum_average_ratings:\n",
    "        print('Not enough ratings for this stock.')\n",
    "        return None, None\n",
    "    else:\n",
    "        first_open=df.iloc[[0]]['Open'].values[0]\n",
    "        last_close=df.iloc[[-1]]['Close'].values[0]\n",
    "        total_return_fraction=last_close/first_open\n",
    "        average_rating=df['Average Assigned Value'].mean()\n",
    "        count_days=df.shape[0]\n",
    "        return_rate = 100*\\\n",
    "            (total_return_fraction**(1/count_days)-1) # Get the daily \n",
    "                            # return rate for the period by taking the n-th root of n-day\n",
    "                                # cumulative stock movements and subtracting 1 (remember the compound interest equation)\n",
    "    return return_rate, average_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9af6b98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for: TFC\n",
      "Recommendation values: ['Buy', 'Equal-Weight', 'Market Perform', 'Neutral', 'Outperform', 'Overweight', 'Underperform']\n",
      "Not enough ratings for this stock.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "stocks = random.sample(sp500,50)\n",
    "store_values = []\n",
    "for stock in stocks:\n",
    "    returns,rating = get_stock_rating_and_return(get_history_and_recommendation_data(stock))\n",
    "    store_values.append([stock,returns,rating])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4ec66e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NFLX', 0.08257080148466045, 3.5644940360508692],\n",
       " ['FDX', 0.01032434118108938, 3.668589152490912],\n",
       " ['RCL', -0.016954628141763184, 3.464143666199191],\n",
       " ['BXP', 0.011169003762057095, 3.0786165301480226],\n",
       " ['MPWR', 0.12942247349450042, 3.9360775572811812]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "580a971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_individual_stock(stock_ticker,period='5y',days_out=180,color_method='Auto',\\\n",
    "                             qlow=0.15,qhigh=0.85,vmin=2.75,vmax=3.75,\\\n",
    "                             returns_method='Period',\\\n",
    "                             min_returns=5,split_size=50):\n",
    "    # Prepare yfinance\n",
    "    print('Results for: '+stock_ticker)\n",
    "    stock=yf.Ticker(stock_ticker)\n",
    "    \n",
    "    # Get historical trading data\n",
    "    try:\n",
    "        history=stock.history(period=period)\n",
    "    except:\n",
    "        print('No history data for '+stock_ticker)\n",
    "        return\n",
    "    \n",
    "    # Get recommendations\n",
    "    days_out = days_out\n",
    "    try:\n",
    "        recommendations=stock.recommendations.reset_index().sort_values(by=['Firm','Date'])\n",
    "    except:\n",
    "        print('No analyst recommendation data for '+stock_ticker)\n",
    "        return\n",
    "    recommendations['Next Recommendation']=recommendations.groupby('Firm')['Date'].shift(-1)\n",
    "    recommendations[str(days_out)+' Days From']=recommendations['Date']+pd.Timedelta(days=days_out)\n",
    "    recommendations['Good Until']=recommendations\\\n",
    "        [['Next Recommendation',str(days_out)+' Days From']]\\\n",
    "            .max(axis=1) # Define how long a recommendation lasts for - lowest of [days_out] or\n",
    "                # [Until a new recommendation by that firm]\n",
    "\n",
    "    # Process the recommendation values\n",
    "    print('Recommendation values: '\\\n",
    "          +str(sorted(recommendations['To Grade'].dropna().unique()))) # Print out the unique recommendation grades\n",
    "    assign_values = {'Buy':4, 'Equal-Weight':3, 'Hold':3, 'Market Perform':3, 'Neutral':3,\n",
    "       'Outperform':4, 'Overweight':4, 'Peer Perform':3, 'Positive':4, 'Reduce':2,\n",
    "       'Sector Perform':3, 'Sector Weight':3, 'Sell':1, 'Strong Buy':5, 'Underperform':1,\n",
    "       'Underweight':1} # Create numeric representations of the recommendations\n",
    "    recommendations['Assigned Value']=\\\n",
    "    recommendations['To Grade'].replace(assign_values) # Give the numeric representations a column\n",
    "    \n",
    "    # Store the dataframes in sqlite memory\n",
    "    conn = sqlite3.connect(':memory:')\n",
    "    history.to_sql('history', conn, index=True)\n",
    "    recommendations.to_sql('recommendations', conn, index=False)\n",
    "    \n",
    "    # Get average analyst assigned scores by day using SQL\n",
    "    qry = '''\n",
    "    select h.open, h.high, h.low, h.close, h.volume, date(h.date) as Date, avg(r.'assigned value') as 'Average Assigned Value'\n",
    "    from history h\n",
    "    left join ( \n",
    "    select * from recommendations r \n",
    "    where r.firm in \n",
    "    (select firm from recommendations group by firm having count(date)>=5)\n",
    "        -- Join recommendations, but only for firms with at least 5 recommendations\n",
    "    ) r\n",
    "    on date(h.date) between date(r.date) and date(r.'good until')\n",
    "    group by h.open, h.high, h.low, h.close, h.volume, date(h.date)\n",
    "        '''\n",
    "    df = pd.read_sql_query(qry, conn).sort_values(by='Date')\n",
    "    df['Date']=pd.to_datetime(df['Date'])\n",
    "\n",
    "        \n",
    "    # Make a plot with background color estimating recommendation sentiment for the periods\n",
    "    # This considers the average recommendation overall\n",
    "    fig,ax = plt.subplots()\n",
    "    df.plot(figsize=(16,16),x='Date',y='Close',ax=ax)\n",
    "    # # Originally used a list color map but change to a scalar map\n",
    "    colormap=colors.LinearSegmentedColormap.from_list('custom',['Red','Yellow','Green'])\n",
    "    # vmin, vmax = 2.5, 4.5 # Manual color definition\n",
    "    if color_method == 'Auto':\n",
    "        qlow = qlow\n",
    "        qhigh = qhigh\n",
    "        vmin = df['Average Assigned Value'].quantile(qlow) # Color definition using quantiles (low)\n",
    "        vmax = df['Average Assigned Value'].quantile(qhigh) # Color definition using quantiles (high)\n",
    "    elif color_method == 'Manual':\n",
    "        vmin = vmin\n",
    "        vmax = vmax\n",
    "    else:\n",
    "        print('Error: Please choose Auto or Manual to define your color scheme.')\n",
    "        return\n",
    "    normalize = colors.Normalize(vmin=vmin,vmax=vmax)\n",
    "    scalarmappaple = cm.ScalarMappable(norm=normalize, cmap=colormap)\n",
    "    for idx, row in df.iterrows():\n",
    "        ax.axvspan(row['Date'],row['Date']+pd.DateOffset(days=1),\\\n",
    "                   alpha=0.2,color=scalarmappaple.to_rgba(row['Average Assigned Value']))\n",
    "    cbar=plt.colorbar(scalarmappaple,label='Average Analyst Recommendation',extend='both',fraction=0.046, pad=0.04)\n",
    "    plt.show()\n",
    "    \n",
    "    # Get a correlation matrix of the current columns\n",
    "    df['Returns']=(df['Close']-df['Close'].shift(1))/df['Close'].shift(1) # Day returns\n",
    "    print('Correlation matrix for all data:')\n",
    "    display(df.corr())\n",
    "    \n",
    "    if returns_method == 'Recommendation Moves':\n",
    "        # Process the dataframe to get columns that can be grouped on the\n",
    "                # analyst average recommendation to show how it affects returns\n",
    "        df['Track Difference Up'] = np.where(df['Average Assigned Value']==df['Average Assigned Value'].shift(1),0,1)\n",
    "        df['Track Difference Down'] = np.where(df['Average Assigned Value']==df['Average Assigned Value'].shift(-1),0,1)\n",
    "        df['Track Difference Unique'] = df['Track Difference Up'].cumsum()\n",
    "        df['First Open'] = np.where(df['Track Difference Up']==1,df['Open'],None)\n",
    "        df['Last Close'] = np.where(df['Track Difference Down']==1,df['Close'],None)\n",
    "\n",
    "        # Get a grouped dataframe with returns data by average analyst recommendation\n",
    "        returns_df = df.groupby(['Track Difference Unique','Average Assigned Value'])\\\n",
    "            .agg({'First Open':'min','Last Close':'max','Returns':'count'}).reset_index()\n",
    "        returns_df['Total Return Fraction']=returns_df['Last Close']/returns_df['First Open']\n",
    "        returns_df['Daily Return']=100*\\\n",
    "            ((returns_df['Total Return Fraction']**(1/returns_df['Returns']))-1) # Get the daily \n",
    "                            # return rate for the period by taking the n-th root of n-day\n",
    "                                # cumulative stock movements and subtracting 1 (remember the compound interest equation)\n",
    "\n",
    "        # Create a dataframe that has at least the minimum days\n",
    "                    # (otherwise 1-day moves could yield high variance, potentially leading to false conclusions)\n",
    "                    # Plot and correlate returns and ratings of that dataframe\n",
    "        min_returns = min_returns\n",
    "        min_returns_df = returns_df[returns_df['Returns']>=min_returns]\n",
    "        min_returns_df.plot(x='Average Assigned Value',y='Daily Return',kind='scatter',figsize=(12,12))\n",
    "        m,b = np.polyfit(x=min_returns_df['Average Assigned Value'],y=min_returns_df['Daily Return'], deg=1)\n",
    "        plt.plot(min_returns_df['Average Assigned Value'],min_returns_df['Average Assigned Value']*m+b)\n",
    "        title = 'R2 Score: '+str(round(r2_score(min_returns_df['Daily Return'],min_returns_df['Average Assigned Value']*m+b),4))\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "        print('Correlation matrix for processed returns data:')\n",
    "        display(min_returns_df.corr())\n",
    "#         display(min_returns_df)\n",
    "    \n",
    "    elif returns_method == 'Period':\n",
    "        # Split the stock into periods and find the return rate during that period as well as the average rating\n",
    "        split_size = split_size\n",
    "        split_bins = math.ceil(df.shape[0]/split_size)\n",
    "        df = pd.read_sql_query(qry, conn).sort_values(by='Date')\n",
    "        df['Date']=pd.to_datetime(df['Date'])\n",
    "        df['Period Group'] = pd.cut(df['Date'],split_bins)\n",
    "        df['First Open'] = df.groupby('Period Group').head(1)['Open']\n",
    "        df['Last Close'] = df.groupby('Period Group').tail(1)['Close']\n",
    "#         display(df)\n",
    "        \n",
    "        # Get a grouped dataframe with returns data for that period to compare against average analyst recommendation\n",
    "        returns_df = df.groupby(['Period Group'])\\\n",
    "        .agg({'First Open':'min','Last Close':'max','Date':'count','Average Assigned Value':'mean'}).reset_index()\n",
    "        returns_df['Total Return Fraction']=returns_df['Last Close']/returns_df['First Open']\n",
    "        returns_df['Daily Return']=100*\\\n",
    "            ((returns_df['Total Return Fraction']**(1/returns_df['Date']))-100)-100 # Get the daily \n",
    "                            # return rate for the period by taking the n-th root of n-day\n",
    "                                # cumulative stock movements and subtracting 1 (remember the compound interest equation)\n",
    "\n",
    "        # Create a dataframe that has at least the minimum days. Get the return for each period bin.\n",
    "                    # Then plot and correlate that dataframe\n",
    "        min_returns_df = returns_df[returns_df['Date']\\\n",
    "                                    >=min(split_size-1,split_size*0.9)] # Each bin\n",
    "                            # for plotting and correlation needs to be at least 90% the size of the split_size\n",
    "        min_returns_df.plot(x='Average Assigned Value',y='Daily Return',kind='scatter',figsize=(12,12))\n",
    "        m,b = np.polyfit(x=min_returns_df['Average Assigned Value'],y=min_returns_df['Daily Return'], deg=1)\n",
    "        plt.plot(min_returns_df['Average Assigned Value'],min_returns_df['Average Assigned Value']*m+b)\n",
    "        title = 'R2 Score: '+\\\n",
    "            str(round(r2_score(min_returns_df['Daily Return'],min_returns_df['Average Assigned Value']*m+b),4))\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "        print('Correlation matrix for processed returns data:')\n",
    "        display(min_returns_df.corr())\n",
    "#         display(min_returns_df)\n",
    "    \n",
    "    else:\n",
    "        print('Error: Please choose Period or Recommendation Moves as your method of returns analysis.')\n",
    "        return\n",
    "    \n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db5adc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
